#First I imported the libraries that I would need to utilize throughout my data analysis for this lab. These libraires included matplotlib.pyplot, pandas, numpy, scipy.stats, seaborn, and sklearn.neighbors. 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import scipy.stats as stats
import seaborn as sbn
from sklearn.neighbors import KernelDensity
import scipy.optimize as optimization
from sklearn.linear_model import LinearRegression
import random

#I mounted my google drive so that I could access the file of data that I downloaded to my drive from my Co-lab notebook. 
from google.colab import drive
drive.mount('/content/drive')

#I plotted the distributions of each of the variables I was most interested in and calculated summary stats for these variables as well (shown in the legend)

f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24,9) )
f.suptitle('Variable Distributions', fontsize = 20)

#Eccentricity 
ax1.hist(data['e'], bins = 50, alpha = 0.4, color = 'BLUE', label = "Mean: 0.14 Standard Deviation: 0.091")
ax1.title.set_text("Eccentricity")
ax1.legend(loc = "upper right", borderpad=0.15)

#Period
ax2.hist(data['per'], bins = 50, alpha = 0.4, color = 'RED', label = "Mean: 2268.4 Standard Deviation: 288.6")
ax2.title.set_text("Period")
ax2.legend(loc = "upper right", borderpad=0.15)

#q
ax3.hist(data['q'], bins = 50, alpha = 0.4, color = 'ORANGE', label = "Mean: 2.89 Standard Deviation: 0.31")
ax3.title.set_text("Perihelion Distance")
ax3.legend(loc = "upper right", borderpad=0.15)


#a
ax4.hist(data['a'],  bins = 50, alpha = 0.4, color = 'PURPLE', label = "Mean: 3.37 Standard Deviation: 0.28")
ax4.title.set_text("Semi Major Axis")
ax4.legend(loc = "upper right", borderpad=0.15)

#Summary statistic calculation 

#Eccentricity
em = data['e'].mean(axis=0)
estd = data['e'].std(axis=0)

#Period
pm = data['per'].mean(axis=0)
pstd = data['per'].std(axis=0)


#Jupiter MOID
mjupm = data['moid_jup'].mean(axis=0)
mjupstd = data['moid_jup'].std(axis=0)

#q
qm = data['q'].mean(axis=0)
qstd = data['q'].std(axis=0)

#a
am = data['a'].mean(axis=0)
astd = data['a'].std(axis=0)

#model fit of q and e, probably used to calculated eachother given the sterngth of the linear fit (q = shortest distance between asteroid and earth, e = eccentricity)
plt.figure(figsize = (10, 10), dpi = 100)
plt.scatter(data['e'], data['q'], alpha = 0.5)
plt.title("Asteroid Eccentricity v Perihelion Distance")
plt.xlabel("Eccentricity")
plt.ylabel("Perihelion Distance au")

#see if there's a clear way to seperate the two streaks by graphing a multi-dimensional graph (color is period, point size is semi-major axis)
datatest = data[['e', 'per', 'q', 'moid_jup', 'a']].dropna(how = 'any')
plt.figure(figsize = (15, 10), dpi = 100)
plt.scatter(datatest['e'], datatest['q'], alpha = 0.5, c = datatest['per'], s = (datatest['a']*10))
plt.colorbar(label = 'Orbital Period (Days)')
plt.title("Asteroid Eccentricity v Perihelion Distance")
plt.xlabel("Eccentricity")
plt.ylabel("Perihelion Distance au")

#Confirmed that I can seperate the data based on period, making two data sets using upper and lower bounds of the period values to include in each sample 
DataA = data[['per','e', 'q', 'a']].dropna(how = 'any')
x = 3000.0
y = 2800.0
for index, row in data.iterrows():
  if ((row['per'] >= x) | (row['per'] <= y)):
    DataA = DataA.drop([index])


DataB = data[['per','e', 'q', 'a']].dropna(how = 'any')
x1= 3000
x2 = 2800
for index, row in data.iterrows():
  if ((row['per'] >= x2) & (row['per'] <= x1)):
    DataB = DataB.drop([index])


#Once I had these distinct groups I plotted the sub-sets of data I created on e v q axis, the original relationship that I wanted to fit with a linear model, over the full data set to confirm that I had split the data up somewhat accurately 
plt.figure(figsize = (10, 10), dpi = 100)
plt.scatter(data['e'], data['q'], alpha = 0.3, color = 'GREEN')
plt.scatter(DataA['e'], DataA['q'], alpha = 0.2, color = 'PURPLE')
plt.scatter(DataB['e'], DataB['q'], alpha = 0.3, color = 'NAVY')
plt.title('Asteroid Eccentricity v Perihelion Distance')
plt.xlabel('Eccentricity')
plt.ylabel('Perihelion Distance')

#Defined a linear equation so that I can do linear regression 
def slopeintfunc(x,sl,incpt):
  return (sl*x)+incpt


#Used Scipy Optimzation and function defined above to make lsrl for the two data sub-sets

#small data set
fit_new1 = optimization.curve_fit(slopeintfunc, DataA['e'],DataA['q'])
slope_new1 = fit_new1[0][0]
inter_new1= fit_new1[0][1]

#larger data set
fit_new2 = optimization.curve_fit(slopeintfunc, DataB['e'],DataB['q'])
slope_new2 = fit_new2[0][0]
inter_new2= fit_new2[0][1]


#Plotted the separate data groups with their respective Least Square Regression Lines

#LSRL
plt.figure(figsize = (12, 12), dpi = 100)
plt.scatter(DataA['e'], DataA['q'], alpha = 0.1, color = 'purple')
plt.scatter(DataB['e'], DataB['q'], alpha = 0.1, color = 'navy')


#smallsamp
plt.plot(DataA['e'], DataA['e']*slope_new1 +inter_new1, color ='magenta', label = 'y = -3.93*x + 3.96')

#largesamp
plt.plot(DataB['e'], DataB['e']*slope_new2 +inter_new2, color ='blue', label = 'y = -3.15*x + 3.25')

plt.legend(loc = "upper right")

plt.title('Asteroid Eccentricity v Perihelion Distance')
plt.xlabel('Eccentricity')
plt.ylabel('Perihelion Distance')

#Residuals

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,9) )
f.suptitle('Residuals', fontsize = 20)

#Data A
predy1 = (DataA['e']*slope_new1)+inter_new1
resid1 = DataA['q'] - predy1
ax1.scatter(predy1, resid1, alpha = 0.3, color ='purple')
ax1.axhline(y=0.0, color = 'magenta')
ax1.title.set_text('Data A Residuals')
ax1.set_xlabel('Predicted Value')
ax1.set_ylabel('Residual')

#Data B
predy2 = (DataB['e']*slope_new2)+inter_new2
resid2 = DataB['q'] - predy2
ax2.scatter(predy2, resid2, alpha = 0.3, color ='navy')
ax2.axhline(y=0.0, color = 'blue')
ax2.title.set_text('Data B Residuals')
ax2.set_xlabel('Predicted Value')
ax2.set_ylabel('Residual')


#I decided to use a KS test as my statistical test for my hypothesis test. I first attempted to 
#do a 2-sample KS test (compares the edcf of two variables). I compared the eccentricities of the Data A and Data B groups

#plot of the data groups + data divisions over eccentricity v period axes 
#three plots 
f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,9), sharex=True, sharey=True )
f.suptitle('All Data, Data Group 1, Data Group 2', fontsize = 20)

#Both Together
ax1.scatter(data['e'],data['per'], alpha = 0.4)
ax1.set_xlabel("Ecc", fontsize = 20)
ax1.set_ylabel("Per", fontsize = 20)
ax1.title.set_text("E vs. Per for Outer Main Belt Asteroids")
ax1.set_yscale('log')
ax1.axhline(y = 2810, color = 'PINK', linestyle = '-', linewidth = 2.0)
ax1.axhline(y = 2970, color = 'PINK', linestyle = '-', linewidth = 2.0)

#Data A
ax2.scatter(DataA['e'], DataA['per'], alpha = 0.4)
ax2.title.set_text("Data Group 1")
ax1.set_yscale('log')
ax2.set_xlabel("Ecc", fontsize = 20)
ax2.set_ylabel("Per", fontsize = 20)


#Data B
ax3.scatter(DataB['e'], DataB['per'], alpha = 0.4)
ax3.title.set_text("Data Group 2")
ax3.set_yscale('log')
ax3.set_xlabel("Ecc", fontsize = 20)
ax3.set_ylabel("Per", fontsize = 20)

#ECDF Function, normalized
def ecdf (data):
  xdatacdf = np.sort(data)
  ydatacdf = np.arange(1, len(data)+1/len(data))
  ydatacdf = ydatacdf/len(data)
  return xdatacdf, ydatacdf


#ECDF overplot 
plt.figure(figsize = (8, 8), dpi = 100)
f.suptitle('Two Sample ECDF Overplot', fontsize = 20)
ax = plt.axes()
x, y = ecdf(DataB['e'])
ax.plot(x, y, marker = '.', linestyle = 'none', alpha = 0.4, color = 'RED', label = 'Data A')
x1, y1 = ecdf(DataA['e'])
ax.plot(x1, y1, marker = '.', linestyle = 'none', alpha = 0.4, color = 'GREEN', label = 'Data B')
ax.legend(loc = 'upper left')

#KS test using Scipy stats built-in functionality 
stats.ks_2samp(DataB['e'], DataA['e'])

#single sample ks test
xcdf1, ycdf1 = ecdf(DataA['e'])
D, p = stats.kstest(DataA, lambda x: np.interp(DataA['e'], xcdf1, ycdf1))
print(D)
print(p)

#single sample ks test
xcdf2, xcdf2 = ecdf(DataB['e'])
D, p = stats.kstest(DataB, lambda x: np.interp(DataB['e'], xcdf2, xcdf2))
print(D)
print(p)

#the two distributions plotted together 
plt.figure(figsize=(8, 8))
ax = plt.axes()
plt.title('Eccentricity Distributions for Small/Large Sample')
plt.xlabel('Eccentricity')
plt.ylabel('Count')
ax.hist(DataA['e'], linestyle = 'none', alpha = 0.4, color = 'GREEN', label = 'small sample')
ax.hist(DataB['e'], linestyle = 'none', alpha = 0.4, color = 'RED', label = 'larger sample')


#make dataframe and set up sample size
tpop = pd.DataFrame()

#same sample size as observed data 
nsamp = 39000

#Mean and stdev of observed population
mean_semia = np.mean(data['a'])
std_semia = np.std(data['a'])

#random True population using observed mean and stdev and high/low limits
def makesample(mean, std, n, low, high):
    sample = np.random.normal(loc=mean, scale=std, size=n)

  #crop simulated points to be within bounds 
    while any(x < low or x > high for x in sample):
        outbound = np.where((sample < low) | (sample > high))[0]
        sample[outbound] = np.random.normal(loc=mean, scale=std, size=len(outbound))

  #simulate kirkwood gaps
    sample = [x for x in sample if x not in [2.06, 2.50, 2.82, 3.28, 3.58]]
    return sample

#add noise to sample 
def noise(data):
  for i in data:
    k = random.uniform(0, 1)
    if (k == 0):
      i = i - random.uniform(0.0, 0.5)
    if (k == 1):
      i = i + random.uniform(0.0, 0.5)
    
#making sample and adding noise using equations above
trued = makesample(mean_semia, std_semia, nsamp, 1, 5)
noise(trued)

#plotting
plt.figure(figsize = (12, 5), dpi = 100)
plt.hist(trued, bins = 100)
plt.xlim(0,4)
plt.title('True Semi-Major Axis Data')
plt.xlabel('Semi Major Axis')
plt.ylabel('Count')


#repeated draws 
fig, ([ax1, ax2, ax3, ax4], [ax5, ax6, ax7, ax8]) = plt.subplots(2, 4, figsize=(15,8), sharey=True, sharex = True)
fig.suptitle('Random Normal Distribution of Semi-Major Axes')
for ax in (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8):
  trued = makesample(mean_semia, std_semia, nsamp, 1, 4)
  noise(trued)
  ax.hist(trued, bins = 100, alpha = 0.5, color = 'red')
  ax.hist(data['a'], bins = 100, alpha = 0.5, color = 'blue')

#Observed data (with trojan resonances highlighted)
plt.figure(figsize = (12, 5), dpi = 100)
plt.hist(data['a'], bins = 100)
plt.axvline(x = 2.06, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 2.50, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 2.82, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 3.28, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 3.58, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 4.29, color = 'PINK', linestyle = '-', linewidth = 2.0)
plt.axvline(x = 5.2, color = 'PINK', linestyle = '-', linewidth = 2.0)

#Observed Data vs. True Data
plt.figure(figsize = (12, 5), dpi = 100)
plt.hist(data['a'], bins = 100, alpha = 0.5, color = 'blue')
plt.hist(trued, bins = 100, alpha = 0.5, color = 'RED')

#make dataframe and set up sample size
tpop = pd.DataFrame()

#same sample size as observed data 
nsamp = 6000

#Mean and stdev of observed population- Hildas
mean_semiaA = np.mean(DataA['a'])
std_semiaA = np.std(DataA['a'])

##Mean and stdev of observed population- Outer Main Belt
mean_semiaB = np.mean(DataB['a'])
std_semiaB = np.std(DataB['a'])

#Data A
fig, ([ax1, ax2, ax3, ax4], [ax5, ax6, ax7, ax8]) = plt.subplots(2, 4, figsize=(15,8), sharey=True, sharex = True)
fig.suptitle('Random Normal Distribution of Semi-Major Axes, Hildas Population')
for ax in (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8):
  trued = makesample(mean_semiaA, std_semiaA, nsamp, 1, 4.1)
  noise(trued)
  ax.hist(DataA['a'], bins = 100, alpha = 0.5, color = 'TEAL')
  ax.hist(trued, bins = 100, alpha = 0.5, color = 'PURPLE')


#Data B
nsamp = 30000
fig, ([ax1, ax2, ax3, ax4], [ax5, ax6, ax7, ax8]) = plt.subplots(2, 4, figsize=(15,8), sharey=True, sharex = True)
fig.suptitle('Random Normal Distribution of Semi-Major Axes')
for ax in (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8):
  trued = makesample(mean_semiaB, std_semiaB, nsamp, 1, 4.1)
  noise(trued)
  ax.hist(trued, bins = 100, alpha = 0.5, color = 'NAVY')
  ax.hist(DataB['a'], bins = 100, alpha = 0.5, color = 'TEAL')
